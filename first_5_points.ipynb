{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import datetime\n",
    "from urllib.request import urlopen\n",
    "import quandl\n",
    "from pandas_datareader.quandl import QuandlReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = 'EZp1zRismtTHsmGpjd2S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 1\n",
    "def filter_data(tickers=[], start_date='', end_date='', additional_columns=[]):\n",
    "    data = pd.read_csv(\"CoreUSFund/SHARADAR-SF1.csv\")\n",
    "\n",
    "    data = data.loc[data['ticker'].isin(tickers)]\n",
    "    data = data[data['calendardate'].between(start_date, end_date, inclusive=True)]\n",
    "    data = data.filter(items=['ticker', 'calendardate'] + additional_columns)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_data(['ZZ', 'ZYXI'], '2007-12-30', '2010-12-31', ['accoci', 'fcf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 2\n",
    "def filter_non_num_data(column_names, column_values):\n",
    "    data = pd.read_csv(\"TickersAndMetaData/SHARADAR-TICKERS.csv\")\n",
    "    \n",
    "    for column_name in column_names:\n",
    "        data = data.loc[data[column_name].isin(column_values)]\n",
    "        \n",
    "    return data['ticker'].to_numpy().tolist()\n",
    "\n",
    "\n",
    "def filter_num_data(tickers=[], start_date='', end_date='', additional_columns=[]):\n",
    "    data = pd.read_csv(\"CoreUSFund/SHARADAR-SF1.csv\")\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        data = data.loc[data['ticker'].isin(tickers)]\n",
    "    \n",
    "    if start_date != '' and end_date != '':\n",
    "        data = data[data['calendardate'].between(start_date, end_date, inclusive=True)]\n",
    "    elif start_date != '' and end_date == '':\n",
    "        data = data[data['calendardate'].between(start_date, datetime.date.today().strftime('%Y-%m-%d'), inclusive=True)]\n",
    "    elif start_date == '' and end_date != '':\n",
    "        data = data[data['calendardate'].between('1998-01-01', end_date, inclusive=True)]\n",
    "        \n",
    "    column_names = []\n",
    "    for additional_column_object in additional_columns:\n",
    "        column_names.append(additional_column_object['column_name'])\n",
    "        \n",
    "    data = data.filter(items=['ticker', 'calendardate'] + column_names)\n",
    "    \n",
    "    for additional_column_object in additional_columns:\n",
    "        for column_name in column_names:\n",
    "            if additional_column_object['artefact'] == '>':\n",
    "                data = data[data[column_name] > additional_column_object['extreme_value']]\n",
    "            elif additional_column_object['artefact'] == '<':\n",
    "                data = data[data[column_name] < additional_column_object['extreme_value']]\n",
    "            elif additional_column_object['artefact'] == '=':\n",
    "                data = data[data[column_name] == additional_column_object['extreme_value']]\n",
    "            elif additional_column_object['artefact'] == '>=':\n",
    "                data = data[data[column_name] >= additional_column_object['extreme_value']]\n",
    "            elif additional_column_object['artefact'] == '<=':\n",
    "                data = data[data[column_name] <= additional_column_object['extreme_value']]\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_num_data(additional_columns=[{'column_name': 'assetturnover', 'extreme_value': 1.6, 'artefact': '<='}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 3\n",
    "def filter_and_sort_data(tickers=[], start_date='', end_date='', sort_by=[]):\n",
    "    final_df = pd.DataFrame(columns=['ticker', 'momentum_score', 'pe_ratio', 'dividend_yield'])\n",
    "    data = pd.read_csv(\"EquityPrices/SHARADAR-SEP.csv\")\n",
    "    data_sf1 = pd.read_csv(\"CoreUSFund/SHARADAR-SF1.csv\")\n",
    "    \n",
    "    # Momentum score, p/e ratio, dividend yield\n",
    "    data = data[data['date'].between(start_date, end_date, inclusive=True)]\n",
    "    data_sf1 = data_sf1[data_sf1['calendardate'].between(start_date, end_date, inclusive=True)]\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        data = data.loc[data['ticker'].isin(tickers)]\n",
    "        data_sf1 = data_sf1.loc[data_sf1['ticker'].isin(tickers)]\n",
    "        \n",
    "    if start_date != '' and end_date != '':\n",
    "        data = data[data['date'].between(start_date, end_date, inclusive=True)]\n",
    "        data_sf1 = data_sf1[data_sf1['calendardate'].between(start_date, end_date, inclusive=True)]\n",
    "    elif start_date != '' and end_date == '':\n",
    "        data = data[data['date'].between(start_date, datetime.date.today().strftime('%Y-%m-%d'), inclusive=True)]\n",
    "        data_sf1 = data_sf1[data_sf1['calendardate'].between(start_date, datetime.date.today().strftime('%Y-%m-%d'), inclusive=True)]\n",
    "    elif start_date == '' and end_date != '':\n",
    "        data = data[data['date'].between('1998-01-01', end_date, inclusive=True)]\n",
    "        data_sf1 = data_sf1[data_sf1['calendardate'].between('1998-01-01', end_date, inclusive=True)]\n",
    "        \n",
    "    unique_tickers = data['ticker'].unique()\n",
    "    helper_data = pd.DataFrame()\n",
    "    helper_data_sf1 = pd.DataFrame()\n",
    "    momentum_score = 0\n",
    "    pe_ratio = 0\n",
    "    dividend_yield = 0\n",
    "    for ticker in unique_tickers:\n",
    "        helper_data = data.loc[data['ticker'].isin([ticker])]\n",
    "        helper_data_sf1 = data_sf1.loc[data_sf1['ticker'].isin([ticker])]\n",
    "        \n",
    "        momentum_score = helper_data['close'].iloc[0] / helper_data['close'].iloc[-1] - 1\n",
    "        pe_ratio = helper_data_sf1['pe'].iloc[0]\n",
    "        dividend_yield = helper_data_sf1['divyield'].iloc[0]\n",
    "        \n",
    "        \n",
    "        final_df = final_df.append(pd.DataFrame(columns=['ticker', 'momentum_score', 'pe_ratio', 'dividend_yield'],\n",
    "                                                data=[[ticker, momentum_score, pe_ratio, dividend_yield]]))\n",
    "    \n",
    "    if (len(sort_by) == 0):\n",
    "        return final_df\n",
    "    \n",
    "    return final_df.sort_values(by=sort_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_and_sort_data([], '2003-01-01', '2010-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 4\n",
    "# a) Inverse Volatility\n",
    "def inverse_volatility(tickers=[], start_date='', end_date=''):\n",
    "    data = pd.read_csv(\"EquityPrices/SHARADAR-SEP.csv\")\n",
    "    final_df = pd.DataFrame(columns=['ticker', 'portfolio_weight'])\n",
    "    \n",
    "    if len(tickers) > 0:\n",
    "        data = data.loc[data['ticker'].isin(tickers)]\n",
    "        \n",
    "    unique_tickers = data['ticker'].unique()\n",
    "    \n",
    "    if start_date != '' and end_date != '':\n",
    "        data = data[data['date'].between(start_date, end_date, inclusive=True)]\n",
    "    elif start_date != '' and end_date == '':\n",
    "        data = data[data['date'].between(start_date, datetime.date.today().strftime('%Y-%m-%d'), inclusive=True)]\n",
    "    elif start_date == '' and end_date != '':\n",
    "        data = data[data['date'].between('1998-01-01', end_date, inclusive=True)]\n",
    "    \n",
    "    for ticker in unique_tickers:\n",
    "        helper_arr = []\n",
    "        helper_data = data.loc[data['ticker'].isin([ticker])]\n",
    "        for i in range(len(helper_data['ticker'])):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            helper_arr.append(helper_data['close'].iloc[i] / helper_data['close'].iloc[i-1] - 1)\n",
    "        \n",
    "        inverse_volatility = 1 / (np.array(helper_arr).std() * np.sqrt(252))\n",
    "        \n",
    "        final_df = final_df.append(pd.DataFrame(columns=['ticker', 'portfolio_weight'],\n",
    "                                                data=[[ticker, inverse_volatility]]))\n",
    "    \n",
    "    final_df.loc[:, 'portfolio_weight'] = final_df['portfolio_weight'].apply(lambda x: x / np.sum(final_df['portfolio_weight']))\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_volatility(['ZZ', 'ZYTO'], '2009-01-01', '2010-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 5\n",
    "def percentiles(data, segment_rank, number_of_segments):\n",
    "    data = data.iloc[int((segment_rank - 1) * len(data['ticker']) / number_of_segments) : \n",
    "                     int(segment_rank * len(data['ticker']) / number_of_segments)]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = filter_and_sort_data([], '2003-01-01', '2010-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>momentum_score</th>\n",
       "      <th>pe_ratio</th>\n",
       "      <th>dividend_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>-0.624113</td>\n",
       "      <td>13.523</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  momentum_score  pe_ratio  dividend_yield\n",
       "0   ZYXI       -0.624113    13.523             0.0"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentiles(test_data, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
